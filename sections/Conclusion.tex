\chapter{Conclusions}

Monte Carlo Regularization is a method for reducing overfitting in neural network training. This thesis's purpose was the proof-of-concept of this regularization, which targets the network's nodes or connections and removes or duplicates them. In doing so, pathological redundancy induced by the training could be eliminated and beneficial generalization redundance inserted into the network. The method's effects have been established; a significant improvement was found on the MNIST for small to medium-sized recurrent neural networks compared to recurrent neural networks of similar size without the method. Further study is required to establish a scaling in the activity of the regularization for larger NNs. The method is general and could be applied to an arbitrary kind of neural network; the reason for using recurrent neural networks is that their non-linear structure complicates structural perturbations' benchmarking.

The study and measurement of the hidden state size were omitted; however, a very rudimentary comment is that allowing for an increase in the hidden layer size directly increases the hidden state's size. Not included was the activity or selection of parameters of the method, which should be adequately studied. The necessary scaling could be established accordingly and possible bias of perturbations. 

The regularization lengthened the training; however, comparatively, the Hessian-free optimization approach was the dominant part of the elapsed time. However, utilizing stochastic gradient descent could reduce the relative times, and optimizing the regularization could then be of importance. Speeding up the process overall, thereby not relying on a supercomputer, is a piece of advice for future study. Also, relying on existing libraries and open-source platforms for machine learning is a protip, not to reinvent the wheel in C++ but rather to depend on the flexibility of giants.

\section{Future work}

The Monte Carlo Regularization hints at a method of initializing a network by continuously perturbing the network pre-training until some threshold value on a cross-validation set is met. 

A way to instead combat the standard deviation instability experienced by the regularization is instead regularizing the parameter update produced in the conjugate gradient method by perturbing and benchmarking the update on a selection set, inspired from micro-canonical sampling, which treats energy as a conserved quantity, to limit the effect on the selection set cross-entropy of a mini-batch update. The analogy is to the demon algorithm, a micro-canonical simulation. A demon considers changes in energy, for example, by producing an extensive update on the selection set and projecting smaller updates from mini-batches to update parameters by considering more information at each mini-batch or randomly benchmarking perturbing the generated updates.

Lastly, regulating the mini-batch size could be done similarly. If the selection set performance goes down during training to increase the mini-batch size and vice versa, somewhat like sampling different temperatures, regulating how much information is considered in each update of the NN parameters. Nevertheless, these two methods relate to further study and are merely concepts derived from statistical physics and this successful regularization technique.